{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61341201",
   "metadata": {},
   "source": [
    "![alt text](img/LM.png)\n",
    "# Kurs: Deep Learning, Text Mining i XAI w Pythonie\n",
    "\n",
    "## Autor: Piotr Ćwiakowski\n",
    "\n",
    "### Lekcja 9. Sieci konwolucyjne (CNN)\n",
    "\n",
    "#### Spis treści\n",
    "\n",
    "1. Wprowadzenie\n",
    "2. Przykład praktyczny - obrazy\n",
    "3. Przykład praktyczny - szeregi czasowe\n",
    "4. Przykład praktyczny - text mining"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc28d633",
   "metadata": {},
   "source": [
    "# 1. Wprowadzenie\n",
    "\n",
    "Konwolucyjne sieci neuronowe (z ang. Convolutional Neural Network, CNN) są sieciami stworzonymi przede wszystkim do klasyfikacji obrazów. Komputer rozumie obraz jako wielowymiarową tablicę o długości i szerokości równej rozdzielczości obrazka i dodatkowo dla każdego piksela (komórki posiada osobną warstwę z wartością dla każdej współrzędnej RGB. CNN potrafi znajdować krawędzie na obrazach, które oddzielają obszary o różnych kolorach – w ten sposób można zbudować bardziej abstrakcyjne koncepty (jak nogi, ręce, oczy etc.) lepiej naśladując ludzki umysł w dokonywaniu klasyfikacji.\n",
    "\n",
    "<img src=\"img/CNN1.png\" width=\"50%\">\n",
    "Źródło: https://adeshpande3.github.io/adeshpande3.github.io/A-Beginner's-Guide-To-Understanding-Convolutional-Neural-Networks/\n",
    "\n",
    "\n",
    "## 1.1 Warstwa konwolucyjna\n",
    "\n",
    "Pierwszą warstwą jest zawsze warstwa konwolucyjna. Pobiera ona, jako jedną obserwację wiele pikseli leżących koło siebie (powiedzmy obszar 5x5 pikseli). Funkcję która pobiera te piksele nazywamy filtrem (czasem także neuronem lub kernelem), a wielkość pobieranego na raz obszaru nazywamy z ang. *receptive field*. Zauważmy, że filtr również jest tablicą liczb (zwanych wagami lub parametrami) – w wypadku obrazów kolorowych 5x5x3 (po jednej na każdy kanał RGB). \n",
    "\n",
    "1. Przyjmijmy teraz, że mamy obraz o wielkości 32x32 i zaczynamy od klastra pikseli w lewym górnym rogu obrazu. \n",
    "2. Dany filtr jest następnie wymnażany przez każdy fragment obrazka (receptive field), który da się wytworzyć z załadowanego obrazu – jest ich łącznie 784 (28x28)\n",
    "3. Dla każdego przypadku, wymnażamy dla każdej warstwy RGB, wymnażamy odpowiadające sobie wartości (tzw. element-wise multiplications) i dodajemy do siebie.\n",
    "4. Każda z 784 par obrazów będzie tworzyła jedną z 784 liczb w macierzy zwanej activation map.\n",
    "5. Im więcej użyjemy filtrów, tym więcej map aktywacyjnych zostanie sporządzonych.\n",
    "\n",
    "<img src=\"img/CNN2.png\" width=\"30%\">\n",
    "Źródło: https://adeshpande3.github.io/adeshpande3.github.io/A-Beginner's-Guide-To-Understanding-Convolutional-Neural-Networks/\n",
    "\n",
    "### Przykład\n",
    "\n",
    "<img src=\"img/CNN3.png\" width=\"60%\">\n",
    "Źródło: https://adeshpande3.github.io/adeshpande3.github.io/A-Beginner's-Guide-To-Understanding-Convolutional-Neural-Networks/\n",
    "\n",
    "<img src=\"img/CNN31.png\" width=\"60%\">\n",
    "Źródło: https://adeshpande3.github.io/adeshpande3.github.io/A-Beginner's-Guide-To-Understanding-Convolutional-Neural-Networks/\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afe7dd7",
   "metadata": {},
   "source": [
    "## 1.2 Stride i padding w CNN\n",
    "\n",
    "### Stride \n",
    "Stride – parametr mówiący o ile przesuwa się „okno” filtra po obrazie. Stride – parametr mówiący o ile przesuwa się „okno” filtra po obrazie.\n",
    "\n",
    "<img src=\"img/CNN4.png\" width=\"50%\">\n",
    "\n",
    "### Padding\n",
    "\n",
    "Padding – parametr okalający obrazek warstwą zer, żeby dane wychodzące z sieci konwolucyjnych miały odpowiedni format. Przykładowo, dla filtru 5x5, obrazka 32x32 i stride = 1 wynik sieci konwolucyjnej będzie wynosił 32x32. Poniżej wzór na wielkość wynikowej obserwacji, gdzie K to wielkość filtra, S to Stride, P – padding, W to długość/wysokość obrazka na wejściu, a O to długość/wysokość na wyjściu.\n",
    "\n",
    "$$O  =\\frac{W-K+2P}{S}+1$$\n",
    "\n",
    "<img src=\"img/CNN5.gif\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92daed63",
   "metadata": {},
   "source": [
    "## 1.3 Pooling layer\n",
    "Po zastosowaniu kilku warstw konwolucyjnych, stosuje się tzw. warstwy łączące, które odlosowują część informacji. Najczęściej są to warstwy stosujące filtr 2x2 o kroku  2. Algorytm przechodzi przez całą tablicę i wybiera z każdego kwadratu największą liczbę. W ten sposób redukuje ilość informacji do najważniejszej jej części. Jednocześnie uodparniamy model na przetrenowanie, ponieważ odzwyczajamy model od konkretnej lokalizacji, uogólniają lokalizację do obszaru 2x2. \n",
    "\n",
    "<img src=\"img/CNN6.png\" width=\"30%\">\n",
    "Źródło: https://adeshpande3.github.io/adeshpande3.github.io/A-Beginner's-Guide-To-Understanding-Convolutional-Neural-Networks/\n",
    "\n",
    "Korzyści otrzymywane z tego zabiegu jest następujące:\n",
    "* zapobiega przetrenowaniu (uogólniając obliczenia),\n",
    "* zmniejsza liczbę parametrów do oszacowania (zmniejszając wielkość informacji),\n",
    "* opiera się na założeniu, że nie ważna jest bezwzględna lokalizacja, wystarczy relatywna względem innych krawędzi."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256e7041",
   "metadata": {},
   "source": [
    "## 1.4 Fully connected layer\n",
    "\n",
    "Sieć konwolucyjna kończy się siecią kilkupoziomową siecią MLP, której celem jest szukanie korelacji pomiędzy klasami a wysokimi wartościami konkretnych warstw aktywacyjnych. Innymi słowy, jeśli CNN wychwytuje konkretne cechy obiektów na zdjęciach MLP patrzy, z którymi cechami dana mapa jest skorelowana.\n",
    "\n",
    "<img src=\"img/CNN7.png\" width=\"30%\">\n",
    "Źródło: http://cs231n.github.io/convolutional-networks/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3536234",
   "metadata": {},
   "source": [
    "## 1.5 Struktura konwolucyjnych sieci neuronowych (CNN)\n",
    "\n",
    "Klasyczne sieci typu CNN są budowane według następującego schematu:\n",
    "<img src=\"img/CNN8.png\" width=\"50%\">\n",
    "\n",
    "1. Sensem pierwszej warstwy jest rozpoznawanie prostych kształtów takich jak proste krawędzie i krzywizny\n",
    "2. W kolejnej warstwie danymi wejściowymi są mapy aktywacyjne – które rozpoznają w których miejscach obrazu znajdują się kształty niskopoziomowe. Druga warstwa konwolucyjna jest w stanie stworzyć z nich koncepty wysokopoziomowe, jak semi-koła lub kwadraty.  Im więcej warstw konwolucyjnych, tym bardziej skomplikowane warstwy można tworzyć. Dzieje się tak m. in. dlatego, że im warstw konwolucyjnych tym szersza jest perspektywa receptive field.\n",
    "3. Istnieje konwencja, aby po każdej warstwie konwolucyjnej (może być ich kilka), umieszczać warstwę aktywacyjną, która wprowadzi nieliniowość do modelu który do tej pory był liniowy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7477a8f",
   "metadata": {},
   "source": [
    "# 2 Przykład aplikacyjny - obrazy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70619b2",
   "metadata": {},
   "source": [
    "## Pakiety"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff07f7b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Ogólne pakiety\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Sieci neuronowe\n",
    "import keras\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Conv2D, MaxPool2D, Flatten\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64978378",
   "metadata": {},
   "source": [
    "## Wczytanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d10aaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape\n",
    "\n",
    "# Policzmy liczbę kategorii\n",
    "num_labels = len(np.unique(y_train))\n",
    "\n",
    "# Zmienna objaśniana musi być w formacie one-hot-encoding\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "y_train.shape, y_test.shape\n",
    "\n",
    "# Normalizacja\n",
    "x_train = x_train/255\n",
    "x_test = x_test/255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59f57ef",
   "metadata": {},
   "source": [
    "## Konstruowanie sieci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05550d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 320\n",
      "Trainable params: 320\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea31f745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "320"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Skąd wzieło się 320 parametrów do trenowania?\n",
    "32 * (3 * 3 + 1) # 32 filtry wielkości 3x3, plus wyraz wolny do kazdego z nich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc2e6b44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dlaczego output shape jest wielkości (None, 26, 26, 32) ?\n",
    "((28 - 3 + 2 * 0) / 1) + 1 # 28 - wielkość wejściowa, 3 - wielkość kernela, 0 - padding, 1 - stride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c8e03b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 320\n",
      "Trainable params: 320\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "133ed371",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Skąd output shape jest wielkości (None, 13, 13, 32) ?\n",
    "26 / 2 # 26 - wielkość wejściowa, 2 - wielkość pool_size,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1be4826b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 5408)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                54090     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 54,410\n",
      "Trainable params: 54,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Spłaszczanie do jednego wymiaru - zamiana wszystkich obserwacji na 1 wymiarowe wektory\n",
    "model.add(Flatten())\n",
    "# Warstwa wyjściowa - 10 klas, funkcja aktywacyjna softmax\n",
    "model.add(Dense(units = 10, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25a912d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5408"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dlaczego output shape w layer_flatten wynosi (None, 5408) ?\n",
    "13 * 13 * 32 # Zerknijmy na output poprzedniej warstwy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2b1396f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54090"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dlaczego liczba parametrów do wytrenowania w ostatniej warstwie wynosi 54090 ?\n",
    "5408 * 10 + 10 # 5408 - z layer_flatten * 10 neuronów + wyrazy wolne"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958c7aa0",
   "metadata": {},
   "source": [
    "## Kompilowanie modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e658fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2720aa",
   "metadata": {},
   "source": [
    "## Trenowanie modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7bc52b07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "422/422 [==============================] - 11s 26ms/step - loss: 0.3707 - accuracy: 0.9008 - val_loss: 0.1343 - val_accuracy: 0.9660\n",
      "Epoch 2/20\n",
      "422/422 [==============================] - 10s 24ms/step - loss: 0.1264 - accuracy: 0.9640 - val_loss: 0.0854 - val_accuracy: 0.9773\n",
      "Epoch 3/20\n",
      "422/422 [==============================] - 13s 30ms/step - loss: 0.0844 - accuracy: 0.9760 - val_loss: 0.0678 - val_accuracy: 0.9822\n",
      "Epoch 4/20\n",
      "422/422 [==============================] - 10s 23ms/step - loss: 0.0672 - accuracy: 0.9807 - val_loss: 0.0604 - val_accuracy: 0.9838\n",
      "Epoch 5/20\n",
      "422/422 [==============================] - 10s 24ms/step - loss: 0.0572 - accuracy: 0.9837 - val_loss: 0.0559 - val_accuracy: 0.9845\n",
      "Epoch 6/20\n",
      "422/422 [==============================] - 10s 23ms/step - loss: 0.0506 - accuracy: 0.9855 - val_loss: 0.0560 - val_accuracy: 0.9845\n",
      "Epoch 7/20\n",
      "422/422 [==============================] - 10s 24ms/step - loss: 0.0457 - accuracy: 0.9864 - val_loss: 0.0549 - val_accuracy: 0.9852\n",
      "Epoch 8/20\n",
      "422/422 [==============================] - 10s 25ms/step - loss: 0.0408 - accuracy: 0.9884 - val_loss: 0.0558 - val_accuracy: 0.9838\n",
      "Epoch 9/20\n",
      "422/422 [==============================] - 10s 24ms/step - loss: 0.0382 - accuracy: 0.9886 - val_loss: 0.0512 - val_accuracy: 0.9862\n",
      "Epoch 10/20\n",
      "422/422 [==============================] - 10s 25ms/step - loss: 0.0349 - accuracy: 0.9893 - val_loss: 0.0558 - val_accuracy: 0.9840\n",
      "Epoch 11/20\n",
      "422/422 [==============================] - 10s 24ms/step - loss: 0.0321 - accuracy: 0.9912 - val_loss: 0.0517 - val_accuracy: 0.9850\n",
      "Epoch 12/20\n",
      "422/422 [==============================] - 11s 25ms/step - loss: 0.0294 - accuracy: 0.9915 - val_loss: 0.0544 - val_accuracy: 0.9862\n",
      "Epoch 13/20\n",
      "422/422 [==============================] - 10s 25ms/step - loss: 0.0267 - accuracy: 0.9923 - val_loss: 0.0537 - val_accuracy: 0.9853\n",
      "Epoch 14/20\n",
      "422/422 [==============================] - 9s 21ms/step - loss: 0.0252 - accuracy: 0.9924 - val_loss: 0.0514 - val_accuracy: 0.9857\n",
      "Epoch 15/20\n",
      "422/422 [==============================] - 10s 24ms/step - loss: 0.0230 - accuracy: 0.9938 - val_loss: 0.0546 - val_accuracy: 0.9870\n",
      "Epoch 16/20\n",
      "422/422 [==============================] - 10s 23ms/step - loss: 0.0209 - accuracy: 0.9939 - val_loss: 0.0527 - val_accuracy: 0.9857\n",
      "Epoch 17/20\n",
      "422/422 [==============================] - 10s 24ms/step - loss: 0.0189 - accuracy: 0.9950 - val_loss: 0.0546 - val_accuracy: 0.9863\n",
      "Epoch 18/20\n",
      "422/422 [==============================] - 10s 24ms/step - loss: 0.0176 - accuracy: 0.9953 - val_loss: 0.0537 - val_accuracy: 0.9865\n",
      "Epoch 19/20\n",
      "422/422 [==============================] - 11s 26ms/step - loss: 0.0165 - accuracy: 0.9957 - val_loss: 0.0552 - val_accuracy: 0.9862\n",
      "Epoch 20/20\n",
      "422/422 [==============================] - 9s 22ms/step - loss: 0.0149 - accuracy: 0.9963 - val_loss: 0.0572 - val_accuracy: 0.9867\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a78770ed40>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 20 \n",
    "# Model trenuje się kilkanaście minut\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efb5000",
   "metadata": {},
   "source": [
    "## Ewaluacja modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "407ba5c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate on test data\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0567 - accuracy: 0.9838\n",
      "test loss, test acc: [0.056731872260570526, 0.9837999939918518]\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluate on test data\")\n",
    "results = model.evaluate(x_test, y_test, batch_size=128)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c2b044",
   "metadata": {},
   "source": [
    "## Więcej informacji\n",
    "* https://machinelearningmastery.com/using-cnn-for-financial-time-series-prediction/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51429c48",
   "metadata": {},
   "source": [
    "# 3 Przykład aplikacyjny - szeregi czasowe\n",
    "\n",
    "Przykład ze strony: https://keras.io/examples/timeseries/timeseries_classification_from_scratch/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840bed0e",
   "metadata": {},
   "source": [
    "### Pakiety"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ee8b259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ogólne pakiety\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Sieci neuronowe\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ba261c",
   "metadata": {},
   "source": [
    "### Wczytanie danych\n",
    "\n",
    "Dane składają się z 3601 szeregów czasowych po 500 obserwacji każdy. Szeregi czasowe należą do dwóch klas (-1 i 1) np. są to ścieżki dźwiękowe piosenek dwóch zespołów Naszym zadaniem jest zbudowanie modelu, który przewiduje klasę ścieżki dźwiękowej. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8428d9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dane wczytujemy z użyciem numpy, od razu dzieląc na zbiór x iy\n",
    "def readucr(filename):\n",
    "    data = np.loadtxt(filename, delimiter=\"\\t\")\n",
    "    y = data[:, 0]\n",
    "    x = data[:, 1:]\n",
    "    return x, y.astype(int)\n",
    "\n",
    "x_train, y_train = readucr(\"data/FordA_TRAIN.tsv\")\n",
    "x_test, y_test = readucr(\"data/FordA_TEST.tsv\")\n",
    "\n",
    "# konwersja klasy -1 na 0\n",
    "y_train[y_train == -1] = 0\n",
    "y_test[y_test == -1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eabacd37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3601, 500), (3601,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17b37cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3601, 500, 1) (1320, 500, 1)\n"
     ]
    }
   ],
   "source": [
    "# Napiszemy procedurę, która pozwoli w przyszłości obsługiwać dane wielokanałowe \n",
    "x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))\n",
    "x_test = x_test.reshape((x_test.shape[0], x_test.shape[1], 1))\n",
    "print(x_train.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "096befe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liczba klas\n",
    "num_classes = len(np.unique(y_train))\n",
    "\n",
    "# Permutacja \n",
    "idx = np.random.permutation(len(x_train))\n",
    "x_train = x_train[idx]\n",
    "y_train = y_train[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c02767",
   "metadata": {},
   "source": [
    "### Zaprojektowanie architektury modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93528e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from importlib import reload\n",
    "# reload(keras.models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41ec99b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(input_shape):\n",
    "    input_layer = keras.layers.Input(input_shape)\n",
    "\n",
    "    conv1 = keras.layers.Conv1D(filters=64, kernel_size=3, padding=\"same\")(input_layer)\n",
    "    conv1 = keras.layers.BatchNormalization()(conv1)\n",
    "    conv1 = keras.layers.ReLU()(conv1)\n",
    "\n",
    "    conv2 = keras.layers.Conv1D(filters=64, kernel_size=3, padding=\"same\")(conv1)\n",
    "    conv2 = keras.layers.BatchNormalization()(conv2)\n",
    "    conv2 = keras.layers.ReLU()(conv2)\n",
    "\n",
    "    conv3 = keras.layers.Conv1D(filters=64, kernel_size=3, padding=\"same\")(conv2)\n",
    "    conv3 = keras.layers.BatchNormalization()(conv3)\n",
    "    conv3 = keras.layers.ReLU()(conv3)\n",
    "\n",
    "    gap = keras.layers.GlobalAveragePooling1D()(conv3)\n",
    "\n",
    "    output_layer = keras.layers.Dense(num_classes, activation=\"softmax\")(gap)\n",
    "\n",
    "    return keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "\n",
    "model = make_model(input_shape=x_train.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4f22c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 500, 1)]          0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 500, 64)           256       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 500, 64)          256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 500, 64)           0         \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 500, 64)           12352     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 500, 64)          256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 500, 64)           0         \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 500, 64)           12352     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 500, 64)          256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_2 (ReLU)              (None, 500, 64)           0         \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 64)               0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,858\n",
      "Trainable params: 25,474\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd86cb96",
   "metadata": {},
   "source": [
    "### Trening modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e00bdf1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "90/90 [==============================] - 8s 58ms/step - loss: 0.3054 - sparse_categorical_accuracy: 0.8708 - val_loss: 0.4154 - val_sparse_categorical_accuracy: 0.7864 - lr: 0.0010\n",
      "Epoch 2/500\n",
      "90/90 [==============================] - 5s 59ms/step - loss: 0.3041 - sparse_categorical_accuracy: 0.8604 - val_loss: 0.4174 - val_sparse_categorical_accuracy: 0.8086 - lr: 0.0010\n",
      "Epoch 3/500\n",
      "90/90 [==============================] - 6s 70ms/step - loss: 0.2964 - sparse_categorical_accuracy: 0.8736 - val_loss: 1.4257 - val_sparse_categorical_accuracy: 0.5035 - lr: 0.0010\n",
      "Epoch 4/500\n",
      "90/90 [==============================] - 6s 63ms/step - loss: 0.2916 - sparse_categorical_accuracy: 0.8722 - val_loss: 0.2834 - val_sparse_categorical_accuracy: 0.8974 - lr: 0.0010\n",
      "Epoch 5/500\n",
      "90/90 [==============================] - 5s 52ms/step - loss: 0.2745 - sparse_categorical_accuracy: 0.8872 - val_loss: 0.9767 - val_sparse_categorical_accuracy: 0.6741 - lr: 0.0010\n",
      "Epoch 6/500\n",
      "90/90 [==============================] - 5s 58ms/step - loss: 0.2920 - sparse_categorical_accuracy: 0.8760 - val_loss: 0.3491 - val_sparse_categorical_accuracy: 0.8252 - lr: 0.0010\n",
      "Epoch 7/500\n",
      "90/90 [==============================] - 5s 54ms/step - loss: 0.2738 - sparse_categorical_accuracy: 0.8840 - val_loss: 0.5028 - val_sparse_categorical_accuracy: 0.7254 - lr: 0.0010\n",
      "Epoch 8/500\n",
      "90/90 [==============================] - 5s 52ms/step - loss: 0.2644 - sparse_categorical_accuracy: 0.8938 - val_loss: 0.3376 - val_sparse_categorical_accuracy: 0.8252 - lr: 0.0010\n",
      "Epoch 9/500\n",
      "90/90 [==============================] - 5s 51ms/step - loss: 0.2737 - sparse_categorical_accuracy: 0.8892 - val_loss: 0.3163 - val_sparse_categorical_accuracy: 0.8571 - lr: 0.0010\n",
      "Epoch 10/500\n",
      "90/90 [==============================] - 6s 63ms/step - loss: 0.2670 - sparse_categorical_accuracy: 0.8882 - val_loss: 0.4244 - val_sparse_categorical_accuracy: 0.7712 - lr: 0.0010\n",
      "Epoch 11/500\n",
      "90/90 [==============================] - 5s 55ms/step - loss: 0.2530 - sparse_categorical_accuracy: 0.9007 - val_loss: 1.8896 - val_sparse_categorical_accuracy: 0.6019 - lr: 0.0010\n",
      "Epoch 12/500\n",
      "90/90 [==============================] - 6s 64ms/step - loss: 0.2599 - sparse_categorical_accuracy: 0.8941 - val_loss: 0.4726 - val_sparse_categorical_accuracy: 0.7739 - lr: 0.0010\n",
      "Epoch 13/500\n",
      "90/90 [==============================] - 5s 58ms/step - loss: 0.2772 - sparse_categorical_accuracy: 0.8813 - val_loss: 0.6433 - val_sparse_categorical_accuracy: 0.7115 - lr: 0.0010\n",
      "Epoch 14/500\n",
      "90/90 [==============================] - 5s 53ms/step - loss: 0.2556 - sparse_categorical_accuracy: 0.8955 - val_loss: 0.6886 - val_sparse_categorical_accuracy: 0.6838 - lr: 0.0010\n",
      "Epoch 15/500\n",
      "90/90 [==============================] - 5s 55ms/step - loss: 0.2608 - sparse_categorical_accuracy: 0.8892 - val_loss: 0.2559 - val_sparse_categorical_accuracy: 0.9001 - lr: 0.0010\n",
      "Epoch 16/500\n",
      "90/90 [==============================] - 5s 52ms/step - loss: 0.2556 - sparse_categorical_accuracy: 0.8917 - val_loss: 0.4444 - val_sparse_categorical_accuracy: 0.8100 - lr: 0.0010\n",
      "Epoch 17/500\n",
      "90/90 [==============================] - 5s 60ms/step - loss: 0.2629 - sparse_categorical_accuracy: 0.8875 - val_loss: 0.7798 - val_sparse_categorical_accuracy: 0.6311 - lr: 0.0010\n",
      "Epoch 18/500\n",
      "90/90 [==============================] - 5s 61ms/step - loss: 0.2460 - sparse_categorical_accuracy: 0.9003 - val_loss: 0.3320 - val_sparse_categorical_accuracy: 0.8294 - lr: 0.0010\n",
      "Epoch 19/500\n",
      "90/90 [==============================] - 5s 57ms/step - loss: 0.2380 - sparse_categorical_accuracy: 0.9024 - val_loss: 0.4204 - val_sparse_categorical_accuracy: 0.7642 - lr: 0.0010\n",
      "Epoch 20/500\n",
      "90/90 [==============================] - 5s 52ms/step - loss: 0.2398 - sparse_categorical_accuracy: 0.9028 - val_loss: 0.9046 - val_sparse_categorical_accuracy: 0.6671 - lr: 0.0010\n",
      "Epoch 21/500\n",
      "90/90 [==============================] - 5s 54ms/step - loss: 0.2489 - sparse_categorical_accuracy: 0.8955 - val_loss: 1.3780 - val_sparse_categorical_accuracy: 0.5465 - lr: 0.0010\n",
      "Epoch 22/500\n",
      "90/90 [==============================] - 5s 55ms/step - loss: 0.2578 - sparse_categorical_accuracy: 0.8979 - val_loss: 1.8642 - val_sparse_categorical_accuracy: 0.4924 - lr: 0.0010\n",
      "Epoch 23/500\n",
      "90/90 [==============================] - 5s 56ms/step - loss: 0.2337 - sparse_categorical_accuracy: 0.9017 - val_loss: 0.4361 - val_sparse_categorical_accuracy: 0.7517 - lr: 0.0010\n",
      "Epoch 24/500\n",
      "90/90 [==============================] - 7s 79ms/step - loss: 0.2421 - sparse_categorical_accuracy: 0.8997 - val_loss: 0.7103 - val_sparse_categorical_accuracy: 0.7101 - lr: 0.0010\n",
      "Epoch 25/500\n",
      "90/90 [==============================] - 8s 87ms/step - loss: 0.2332 - sparse_categorical_accuracy: 0.9069 - val_loss: 0.2392 - val_sparse_categorical_accuracy: 0.9140 - lr: 0.0010\n",
      "Epoch 26/500\n",
      "90/90 [==============================] - 5s 58ms/step - loss: 0.2389 - sparse_categorical_accuracy: 0.8990 - val_loss: 0.3655 - val_sparse_categorical_accuracy: 0.8086 - lr: 0.0010\n",
      "Epoch 27/500\n",
      "90/90 [==============================] - 6s 70ms/step - loss: 0.2314 - sparse_categorical_accuracy: 0.9073 - val_loss: 1.7016 - val_sparse_categorical_accuracy: 0.6394 - lr: 0.0010\n",
      "Epoch 28/500\n",
      "90/90 [==============================] - 5s 52ms/step - loss: 0.2243 - sparse_categorical_accuracy: 0.9142 - val_loss: 0.5023 - val_sparse_categorical_accuracy: 0.7337 - lr: 0.0010\n",
      "Epoch 29/500\n",
      "90/90 [==============================] - 5s 59ms/step - loss: 0.2208 - sparse_categorical_accuracy: 0.9087 - val_loss: 1.1964 - val_sparse_categorical_accuracy: 0.5784 - lr: 0.0010\n",
      "Epoch 30/500\n",
      "90/90 [==============================] - 5s 52ms/step - loss: 0.2424 - sparse_categorical_accuracy: 0.9014 - val_loss: 0.2667 - val_sparse_categorical_accuracy: 0.8863 - lr: 0.0010\n",
      "Epoch 31/500\n",
      "90/90 [==============================] - 5s 56ms/step - loss: 0.2230 - sparse_categorical_accuracy: 0.9128 - val_loss: 0.9015 - val_sparse_categorical_accuracy: 0.6394 - lr: 0.0010\n",
      "Epoch 32/500\n",
      "90/90 [==============================] - 5s 53ms/step - loss: 0.2212 - sparse_categorical_accuracy: 0.9094 - val_loss: 0.5414 - val_sparse_categorical_accuracy: 0.7601 - lr: 0.0010\n",
      "Epoch 33/500\n",
      "90/90 [==============================] - 5s 53ms/step - loss: 0.2410 - sparse_categorical_accuracy: 0.8983 - val_loss: 0.9019 - val_sparse_categorical_accuracy: 0.6727 - lr: 0.0010\n",
      "Epoch 34/500\n",
      "90/90 [==============================] - 5s 52ms/step - loss: 0.2253 - sparse_categorical_accuracy: 0.9115 - val_loss: 1.1960 - val_sparse_categorical_accuracy: 0.6990 - lr: 0.0010\n",
      "Epoch 35/500\n",
      "90/90 [==============================] - 5s 52ms/step - loss: 0.2305 - sparse_categorical_accuracy: 0.9069 - val_loss: 0.2757 - val_sparse_categorical_accuracy: 0.8946 - lr: 0.0010\n",
      "Epoch 36/500\n",
      "90/90 [==============================] - 5s 53ms/step - loss: 0.2203 - sparse_categorical_accuracy: 0.9125 - val_loss: 0.2510 - val_sparse_categorical_accuracy: 0.8766 - lr: 0.0010\n",
      "Epoch 37/500\n",
      "90/90 [==============================] - 7s 74ms/step - loss: 0.2207 - sparse_categorical_accuracy: 0.9128 - val_loss: 0.3463 - val_sparse_categorical_accuracy: 0.8350 - lr: 0.0010\n",
      "Epoch 38/500\n",
      "90/90 [==============================] - 5s 57ms/step - loss: 0.2228 - sparse_categorical_accuracy: 0.9104 - val_loss: 0.3526 - val_sparse_categorical_accuracy: 0.8294 - lr: 0.0010\n",
      "Epoch 39/500\n",
      "90/90 [==============================] - 5s 54ms/step - loss: 0.1975 - sparse_categorical_accuracy: 0.9247 - val_loss: 0.2236 - val_sparse_categorical_accuracy: 0.9098 - lr: 0.0010\n",
      "Epoch 40/500\n",
      "90/90 [==============================] - 5s 55ms/step - loss: 0.1942 - sparse_categorical_accuracy: 0.9243 - val_loss: 0.1950 - val_sparse_categorical_accuracy: 0.9417 - lr: 0.0010\n",
      "Epoch 41/500\n",
      "90/90 [==============================] - 8s 92ms/step - loss: 0.1965 - sparse_categorical_accuracy: 0.9243 - val_loss: 0.2824 - val_sparse_categorical_accuracy: 0.8558 - lr: 0.0010\n",
      "Epoch 42/500\n",
      "90/90 [==============================] - 6s 65ms/step - loss: 0.2083 - sparse_categorical_accuracy: 0.9177 - val_loss: 0.4558 - val_sparse_categorical_accuracy: 0.7517 - lr: 0.0010\n",
      "Epoch 43/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 6s 63ms/step - loss: 0.1752 - sparse_categorical_accuracy: 0.9340 - val_loss: 0.4387 - val_sparse_categorical_accuracy: 0.8100 - lr: 0.0010\n",
      "Epoch 44/500\n",
      "90/90 [==============================] - 5s 53ms/step - loss: 0.1837 - sparse_categorical_accuracy: 0.9306 - val_loss: 1.0438 - val_sparse_categorical_accuracy: 0.5700 - lr: 0.0010\n",
      "Epoch 45/500\n",
      "90/90 [==============================] - 5s 53ms/step - loss: 0.1733 - sparse_categorical_accuracy: 0.9347 - val_loss: 0.3790 - val_sparse_categorical_accuracy: 0.8350 - lr: 0.0010\n",
      "Epoch 46/500\n",
      "90/90 [==============================] - 5s 58ms/step - loss: 0.1468 - sparse_categorical_accuracy: 0.9503 - val_loss: 0.1832 - val_sparse_categorical_accuracy: 0.9362 - lr: 0.0010\n",
      "Epoch 47/500\n",
      "90/90 [==============================] - 5s 54ms/step - loss: 0.1540 - sparse_categorical_accuracy: 0.9448 - val_loss: 0.2339 - val_sparse_categorical_accuracy: 0.8974 - lr: 0.0010\n",
      "Epoch 48/500\n",
      "90/90 [==============================] - 5s 56ms/step - loss: 0.1476 - sparse_categorical_accuracy: 0.9521 - val_loss: 1.4841 - val_sparse_categorical_accuracy: 0.7171 - lr: 0.0010\n",
      "Epoch 49/500\n",
      "90/90 [==============================] - 7s 78ms/step - loss: 0.1534 - sparse_categorical_accuracy: 0.9462 - val_loss: 0.1350 - val_sparse_categorical_accuracy: 0.9515 - lr: 0.0010\n",
      "Epoch 50/500\n",
      "90/90 [==============================] - 6s 69ms/step - loss: 0.1393 - sparse_categorical_accuracy: 0.9497 - val_loss: 0.5668 - val_sparse_categorical_accuracy: 0.6879 - lr: 0.0010\n",
      "Epoch 51/500\n",
      "90/90 [==============================] - 5s 56ms/step - loss: 0.1543 - sparse_categorical_accuracy: 0.9469 - val_loss: 0.3064 - val_sparse_categorical_accuracy: 0.8502 - lr: 0.0010\n",
      "Epoch 52/500\n",
      "90/90 [==============================] - 5s 57ms/step - loss: 0.1322 - sparse_categorical_accuracy: 0.9531 - val_loss: 0.2602 - val_sparse_categorical_accuracy: 0.8807 - lr: 0.0010\n",
      "Epoch 53/500\n",
      "90/90 [==============================] - 5s 53ms/step - loss: 0.1356 - sparse_categorical_accuracy: 0.9517 - val_loss: 0.2090 - val_sparse_categorical_accuracy: 0.9168 - lr: 0.0010\n",
      "Epoch 54/500\n",
      "90/90 [==============================] - 5s 51ms/step - loss: 0.1331 - sparse_categorical_accuracy: 0.9556 - val_loss: 0.1923 - val_sparse_categorical_accuracy: 0.9362 - lr: 0.0010\n",
      "Epoch 55/500\n",
      "90/90 [==============================] - 5s 58ms/step - loss: 0.1262 - sparse_categorical_accuracy: 0.9615 - val_loss: 1.8957 - val_sparse_categorical_accuracy: 0.4896 - lr: 0.0010\n",
      "Epoch 56/500\n",
      "90/90 [==============================] - 5s 52ms/step - loss: 0.1383 - sparse_categorical_accuracy: 0.9521 - val_loss: 0.3279 - val_sparse_categorical_accuracy: 0.8613 - lr: 0.0010\n",
      "Epoch 57/500\n",
      "90/90 [==============================] - 4s 49ms/step - loss: 0.1296 - sparse_categorical_accuracy: 0.9556 - val_loss: 0.1391 - val_sparse_categorical_accuracy: 0.9501 - lr: 0.0010\n",
      "Epoch 58/500\n",
      "90/90 [==============================] - 5s 51ms/step - loss: 0.1231 - sparse_categorical_accuracy: 0.9559 - val_loss: 1.1859 - val_sparse_categorical_accuracy: 0.6824 - lr: 0.0010\n",
      "Epoch 59/500\n",
      "90/90 [==============================] - 5s 55ms/step - loss: 0.1206 - sparse_categorical_accuracy: 0.9597 - val_loss: 0.2673 - val_sparse_categorical_accuracy: 0.8696 - lr: 0.0010\n",
      "Epoch 60/500\n",
      "90/90 [==============================] - 5s 54ms/step - loss: 0.1221 - sparse_categorical_accuracy: 0.9576 - val_loss: 0.2032 - val_sparse_categorical_accuracy: 0.9140 - lr: 0.0010\n",
      "Epoch 61/500\n",
      "90/90 [==============================] - 5s 52ms/step - loss: 0.1269 - sparse_categorical_accuracy: 0.9576 - val_loss: 0.4174 - val_sparse_categorical_accuracy: 0.7809 - lr: 0.0010\n",
      "Epoch 62/500\n",
      "90/90 [==============================] - 7s 72ms/step - loss: 0.1259 - sparse_categorical_accuracy: 0.9552 - val_loss: 0.1629 - val_sparse_categorical_accuracy: 0.9293 - lr: 0.0010\n",
      "Epoch 63/500\n",
      "90/90 [==============================] - 5s 57ms/step - loss: 0.1185 - sparse_categorical_accuracy: 0.9569 - val_loss: 0.4505 - val_sparse_categorical_accuracy: 0.8058 - lr: 0.0010\n",
      "Epoch 64/500\n",
      "90/90 [==============================] - 5s 53ms/step - loss: 0.1194 - sparse_categorical_accuracy: 0.9587 - val_loss: 0.1409 - val_sparse_categorical_accuracy: 0.9459 - lr: 0.0010\n",
      "Epoch 65/500\n",
      "90/90 [==============================] - 5s 55ms/step - loss: 0.1202 - sparse_categorical_accuracy: 0.9604 - val_loss: 0.2258 - val_sparse_categorical_accuracy: 0.8863 - lr: 0.0010\n",
      "Epoch 66/500\n",
      "90/90 [==============================] - 5s 57ms/step - loss: 0.1210 - sparse_categorical_accuracy: 0.9611 - val_loss: 1.1700 - val_sparse_categorical_accuracy: 0.7143 - lr: 0.0010\n",
      "Epoch 67/500\n",
      "90/90 [==============================] - 7s 79ms/step - loss: 0.1136 - sparse_categorical_accuracy: 0.9615 - val_loss: 0.2533 - val_sparse_categorical_accuracy: 0.8766 - lr: 0.0010\n",
      "Epoch 68/500\n",
      "90/90 [==============================] - 5s 53ms/step - loss: 0.1152 - sparse_categorical_accuracy: 0.9573 - val_loss: 2.5002 - val_sparse_categorical_accuracy: 0.6990 - lr: 0.0010\n",
      "Epoch 69/500\n",
      "90/90 [==============================] - 5s 51ms/step - loss: 0.1192 - sparse_categorical_accuracy: 0.9604 - val_loss: 0.3202 - val_sparse_categorical_accuracy: 0.8599 - lr: 0.0010\n",
      "Epoch 70/500\n",
      "90/90 [==============================] - 5s 59ms/step - loss: 0.1106 - sparse_categorical_accuracy: 0.9618 - val_loss: 0.1084 - val_sparse_categorical_accuracy: 0.9667 - lr: 5.0000e-04\n",
      "Epoch 71/500\n",
      "90/90 [==============================] - 5s 51ms/step - loss: 0.1088 - sparse_categorical_accuracy: 0.9632 - val_loss: 0.7887 - val_sparse_categorical_accuracy: 0.7406 - lr: 5.0000e-04\n",
      "Epoch 72/500\n",
      "90/90 [==============================] - 5s 53ms/step - loss: 0.0968 - sparse_categorical_accuracy: 0.9660 - val_loss: 0.3090 - val_sparse_categorical_accuracy: 0.8544 - lr: 5.0000e-04\n",
      "Epoch 73/500\n",
      "90/90 [==============================] - 5s 51ms/step - loss: 0.1025 - sparse_categorical_accuracy: 0.9649 - val_loss: 0.1733 - val_sparse_categorical_accuracy: 0.9209 - lr: 5.0000e-04\n",
      "Epoch 74/500\n",
      "90/90 [==============================] - 5s 60ms/step - loss: 0.1024 - sparse_categorical_accuracy: 0.9660 - val_loss: 0.1456 - val_sparse_categorical_accuracy: 0.9501 - lr: 5.0000e-04\n",
      "Epoch 75/500\n",
      "90/90 [==============================] - 6s 64ms/step - loss: 0.0927 - sparse_categorical_accuracy: 0.9677 - val_loss: 0.1015 - val_sparse_categorical_accuracy: 0.9681 - lr: 5.0000e-04\n",
      "Epoch 76/500\n",
      "90/90 [==============================] - 5s 53ms/step - loss: 0.0917 - sparse_categorical_accuracy: 0.9726 - val_loss: 0.0925 - val_sparse_categorical_accuracy: 0.9626 - lr: 5.0000e-04\n",
      "Epoch 77/500\n",
      "90/90 [==============================] - 5s 51ms/step - loss: 0.1013 - sparse_categorical_accuracy: 0.9618 - val_loss: 0.1013 - val_sparse_categorical_accuracy: 0.9639 - lr: 5.0000e-04\n",
      "Epoch 78/500\n",
      "90/90 [==============================] - 5s 52ms/step - loss: 0.0958 - sparse_categorical_accuracy: 0.9677 - val_loss: 0.0872 - val_sparse_categorical_accuracy: 0.9723 - lr: 5.0000e-04\n",
      "Epoch 79/500\n",
      "90/90 [==============================] - 5s 54ms/step - loss: 0.0930 - sparse_categorical_accuracy: 0.9701 - val_loss: 0.1259 - val_sparse_categorical_accuracy: 0.9639 - lr: 5.0000e-04\n",
      "Epoch 80/500\n",
      "90/90 [==============================] - 5s 52ms/step - loss: 0.0883 - sparse_categorical_accuracy: 0.9694 - val_loss: 0.2000 - val_sparse_categorical_accuracy: 0.9140 - lr: 5.0000e-04\n",
      "Epoch 81/500\n",
      "90/90 [==============================] - 5s 53ms/step - loss: 0.0909 - sparse_categorical_accuracy: 0.9705 - val_loss: 1.1727 - val_sparse_categorical_accuracy: 0.6921 - lr: 5.0000e-04\n",
      "Epoch 82/500\n",
      "90/90 [==============================] - 5s 51ms/step - loss: 0.0914 - sparse_categorical_accuracy: 0.9688 - val_loss: 0.6656 - val_sparse_categorical_accuracy: 0.7573 - lr: 5.0000e-04\n",
      "Epoch 83/500\n",
      "90/90 [==============================] - 5s 50ms/step - loss: 0.0958 - sparse_categorical_accuracy: 0.9698 - val_loss: 0.2996 - val_sparse_categorical_accuracy: 0.8682 - lr: 5.0000e-04\n",
      "Epoch 84/500\n",
      "90/90 [==============================] - 5s 53ms/step - loss: 0.0895 - sparse_categorical_accuracy: 0.9726 - val_loss: 0.6008 - val_sparse_categorical_accuracy: 0.7809 - lr: 5.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/500\n",
      "90/90 [==============================] - 5s 51ms/step - loss: 0.0926 - sparse_categorical_accuracy: 0.9698 - val_loss: 0.3599 - val_sparse_categorical_accuracy: 0.8405 - lr: 5.0000e-04\n",
      "Epoch 86/500\n",
      "90/90 [==============================] - 5s 52ms/step - loss: 0.0926 - sparse_categorical_accuracy: 0.9691 - val_loss: 0.2530 - val_sparse_categorical_accuracy: 0.8849 - lr: 5.0000e-04\n",
      "Epoch 87/500\n",
      "90/90 [==============================] - 5s 51ms/step - loss: 0.0979 - sparse_categorical_accuracy: 0.9670 - val_loss: 0.3403 - val_sparse_categorical_accuracy: 0.8558 - lr: 5.0000e-04\n",
      "Epoch 88/500\n",
      "90/90 [==============================] - 5s 56ms/step - loss: 0.1017 - sparse_categorical_accuracy: 0.9653 - val_loss: 0.2117 - val_sparse_categorical_accuracy: 0.9043 - lr: 5.0000e-04\n",
      "Epoch 89/500\n",
      "90/90 [==============================] - 5s 60ms/step - loss: 0.0971 - sparse_categorical_accuracy: 0.9677 - val_loss: 0.1033 - val_sparse_categorical_accuracy: 0.9626 - lr: 5.0000e-04\n",
      "Epoch 90/500\n",
      "90/90 [==============================] - 5s 51ms/step - loss: 0.0953 - sparse_categorical_accuracy: 0.9674 - val_loss: 0.1253 - val_sparse_categorical_accuracy: 0.9528 - lr: 5.0000e-04\n",
      "Epoch 91/500\n",
      "90/90 [==============================] - 5s 52ms/step - loss: 0.1034 - sparse_categorical_accuracy: 0.9656 - val_loss: 0.1351 - val_sparse_categorical_accuracy: 0.9445 - lr: 5.0000e-04\n",
      "Epoch 92/500\n",
      "90/90 [==============================] - 2s 26ms/step - loss: 0.0981 - sparse_categorical_accuracy: 0.9608 - val_loss: 0.1076 - val_sparse_categorical_accuracy: 0.9556 - lr: 5.0000e-04\n",
      "Epoch 93/500\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 0.1003 - sparse_categorical_accuracy: 0.9639 - val_loss: 0.0914 - val_sparse_categorical_accuracy: 0.9639 - lr: 5.0000e-04\n",
      "Epoch 94/500\n",
      "90/90 [==============================] - 5s 56ms/step - loss: 0.0949 - sparse_categorical_accuracy: 0.9715 - val_loss: 0.1265 - val_sparse_categorical_accuracy: 0.9445 - lr: 5.0000e-04\n",
      "Epoch 95/500\n",
      "90/90 [==============================] - 5s 52ms/step - loss: 0.0906 - sparse_categorical_accuracy: 0.9691 - val_loss: 0.0981 - val_sparse_categorical_accuracy: 0.9667 - lr: 5.0000e-04\n",
      "Epoch 96/500\n",
      "90/90 [==============================] - 5s 59ms/step - loss: 0.0877 - sparse_categorical_accuracy: 0.9712 - val_loss: 0.3599 - val_sparse_categorical_accuracy: 0.8280 - lr: 5.0000e-04\n",
      "Epoch 97/500\n",
      "90/90 [==============================] - 5s 54ms/step - loss: 0.0894 - sparse_categorical_accuracy: 0.9694 - val_loss: 0.1631 - val_sparse_categorical_accuracy: 0.9307 - lr: 5.0000e-04\n",
      "Epoch 98/500\n",
      "90/90 [==============================] - 4s 50ms/step - loss: 0.0893 - sparse_categorical_accuracy: 0.9712 - val_loss: 0.0872 - val_sparse_categorical_accuracy: 0.9681 - lr: 5.0000e-04\n",
      "Epoch 99/500\n",
      "90/90 [==============================] - 5s 57ms/step - loss: 0.0828 - sparse_categorical_accuracy: 0.9726 - val_loss: 0.1040 - val_sparse_categorical_accuracy: 0.9556 - lr: 2.5000e-04\n",
      "Epoch 100/500\n",
      "90/90 [==============================] - 5s 51ms/step - loss: 0.0858 - sparse_categorical_accuracy: 0.9715 - val_loss: 0.0939 - val_sparse_categorical_accuracy: 0.9653 - lr: 2.5000e-04\n",
      "Epoch 101/500\n",
      "90/90 [==============================] - 5s 57ms/step - loss: 0.0858 - sparse_categorical_accuracy: 0.9681 - val_loss: 0.0861 - val_sparse_categorical_accuracy: 0.9723 - lr: 2.5000e-04\n",
      "Epoch 102/500\n",
      "90/90 [==============================] - 6s 63ms/step - loss: 0.0853 - sparse_categorical_accuracy: 0.9708 - val_loss: 0.0826 - val_sparse_categorical_accuracy: 0.9736 - lr: 2.5000e-04\n",
      "Epoch 103/500\n",
      "90/90 [==============================] - 7s 76ms/step - loss: 0.0887 - sparse_categorical_accuracy: 0.9712 - val_loss: 0.0992 - val_sparse_categorical_accuracy: 0.9598 - lr: 2.5000e-04\n",
      "Epoch 104/500\n",
      "90/90 [==============================] - 5s 59ms/step - loss: 0.0873 - sparse_categorical_accuracy: 0.9694 - val_loss: 0.0920 - val_sparse_categorical_accuracy: 0.9681 - lr: 2.5000e-04\n",
      "Epoch 105/500\n",
      "90/90 [==============================] - 5s 58ms/step - loss: 0.0806 - sparse_categorical_accuracy: 0.9722 - val_loss: 0.0853 - val_sparse_categorical_accuracy: 0.9723 - lr: 2.5000e-04\n",
      "Epoch 106/500\n",
      "90/90 [==============================] - 5s 55ms/step - loss: 0.0797 - sparse_categorical_accuracy: 0.9715 - val_loss: 0.0850 - val_sparse_categorical_accuracy: 0.9709 - lr: 2.5000e-04\n",
      "Epoch 107/500\n",
      "90/90 [==============================] - 5s 53ms/step - loss: 0.0869 - sparse_categorical_accuracy: 0.9701 - val_loss: 0.0928 - val_sparse_categorical_accuracy: 0.9681 - lr: 2.5000e-04\n",
      "Epoch 108/500\n",
      "90/90 [==============================] - 5s 53ms/step - loss: 0.0857 - sparse_categorical_accuracy: 0.9694 - val_loss: 0.0842 - val_sparse_categorical_accuracy: 0.9695 - lr: 2.5000e-04\n",
      "Epoch 109/500\n",
      "90/90 [==============================] - 5s 56ms/step - loss: 0.0786 - sparse_categorical_accuracy: 0.9753 - val_loss: 0.0819 - val_sparse_categorical_accuracy: 0.9709 - lr: 2.5000e-04\n",
      "Epoch 110/500\n",
      "90/90 [==============================] - 5s 54ms/step - loss: 0.0779 - sparse_categorical_accuracy: 0.9747 - val_loss: 0.0791 - val_sparse_categorical_accuracy: 0.9653 - lr: 2.5000e-04\n",
      "Epoch 111/500\n",
      "90/90 [==============================] - 5s 55ms/step - loss: 0.0816 - sparse_categorical_accuracy: 0.9722 - val_loss: 0.1509 - val_sparse_categorical_accuracy: 0.9431 - lr: 2.5000e-04\n",
      "Epoch 112/500\n",
      "90/90 [==============================] - 5s 52ms/step - loss: 0.0833 - sparse_categorical_accuracy: 0.9677 - val_loss: 0.0879 - val_sparse_categorical_accuracy: 0.9681 - lr: 2.5000e-04\n",
      "Epoch 113/500\n",
      "90/90 [==============================] - 5s 53ms/step - loss: 0.0790 - sparse_categorical_accuracy: 0.9733 - val_loss: 0.1080 - val_sparse_categorical_accuracy: 0.9570 - lr: 2.5000e-04\n",
      "Epoch 114/500\n",
      "90/90 [==============================] - 5s 52ms/step - loss: 0.0810 - sparse_categorical_accuracy: 0.9750 - val_loss: 0.0854 - val_sparse_categorical_accuracy: 0.9695 - lr: 2.5000e-04\n",
      "Epoch 115/500\n",
      "90/90 [==============================] - 5s 59ms/step - loss: 0.0790 - sparse_categorical_accuracy: 0.9753 - val_loss: 0.0795 - val_sparse_categorical_accuracy: 0.9750 - lr: 2.5000e-04\n",
      "Epoch 116/500\n",
      "90/90 [==============================] - 5s 59ms/step - loss: 0.0793 - sparse_categorical_accuracy: 0.9736 - val_loss: 0.2828 - val_sparse_categorical_accuracy: 0.8779 - lr: 2.5000e-04\n",
      "Epoch 117/500\n",
      "90/90 [==============================] - 5s 52ms/step - loss: 0.0798 - sparse_categorical_accuracy: 0.9733 - val_loss: 0.1717 - val_sparse_categorical_accuracy: 0.9390 - lr: 2.5000e-04\n",
      "Epoch 118/500\n",
      "90/90 [==============================] - 7s 77ms/step - loss: 0.0821 - sparse_categorical_accuracy: 0.9708 - val_loss: 0.1451 - val_sparse_categorical_accuracy: 0.9431 - lr: 2.5000e-04\n",
      "Epoch 119/500\n",
      "90/90 [==============================] - 5s 56ms/step - loss: 0.0798 - sparse_categorical_accuracy: 0.9747 - val_loss: 0.0968 - val_sparse_categorical_accuracy: 0.9667 - lr: 2.5000e-04\n",
      "Epoch 120/500\n",
      "90/90 [==============================] - 7s 80ms/step - loss: 0.0871 - sparse_categorical_accuracy: 0.9705 - val_loss: 0.1021 - val_sparse_categorical_accuracy: 0.9612 - lr: 2.5000e-04\n",
      "Epoch 121/500\n",
      "90/90 [==============================] - 9s 102ms/step - loss: 0.0851 - sparse_categorical_accuracy: 0.9705 - val_loss: 0.1310 - val_sparse_categorical_accuracy: 0.9515 - lr: 2.5000e-04\n",
      "Epoch 122/500\n",
      "90/90 [==============================] - 5s 52ms/step - loss: 0.0770 - sparse_categorical_accuracy: 0.9753 - val_loss: 0.1801 - val_sparse_categorical_accuracy: 0.9293 - lr: 2.5000e-04\n",
      "Epoch 123/500\n",
      "90/90 [==============================] - 5s 57ms/step - loss: 0.0840 - sparse_categorical_accuracy: 0.9712 - val_loss: 0.0832 - val_sparse_categorical_accuracy: 0.9667 - lr: 2.5000e-04\n",
      "Epoch 124/500\n",
      "90/90 [==============================] - 5s 51ms/step - loss: 0.0793 - sparse_categorical_accuracy: 0.9750 - val_loss: 0.1305 - val_sparse_categorical_accuracy: 0.9445 - lr: 2.5000e-04\n",
      "Epoch 125/500\n",
      "90/90 [==============================] - 6s 67ms/step - loss: 0.0800 - sparse_categorical_accuracy: 0.9701 - val_loss: 0.1261 - val_sparse_categorical_accuracy: 0.9528 - lr: 2.5000e-04\n",
      "Epoch 126/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 5s 51ms/step - loss: 0.0719 - sparse_categorical_accuracy: 0.9774 - val_loss: 0.0975 - val_sparse_categorical_accuracy: 0.9584 - lr: 2.5000e-04\n",
      "Epoch 127/500\n",
      "90/90 [==============================] - 6s 71ms/step - loss: 0.0832 - sparse_categorical_accuracy: 0.9708 - val_loss: 0.0844 - val_sparse_categorical_accuracy: 0.9653 - lr: 2.5000e-04\n",
      "Epoch 128/500\n",
      "90/90 [==============================] - 5s 56ms/step - loss: 0.0702 - sparse_categorical_accuracy: 0.9781 - val_loss: 0.0774 - val_sparse_categorical_accuracy: 0.9709 - lr: 2.5000e-04\n",
      "Epoch 129/500\n",
      "90/90 [==============================] - 5s 54ms/step - loss: 0.0805 - sparse_categorical_accuracy: 0.9726 - val_loss: 0.0808 - val_sparse_categorical_accuracy: 0.9681 - lr: 2.5000e-04\n",
      "Epoch 130/500\n",
      "90/90 [==============================] - 5s 60ms/step - loss: 0.0836 - sparse_categorical_accuracy: 0.9708 - val_loss: 0.0774 - val_sparse_categorical_accuracy: 0.9723 - lr: 2.5000e-04\n",
      "Epoch 131/500\n",
      "90/90 [==============================] - 5s 60ms/step - loss: 0.0769 - sparse_categorical_accuracy: 0.9736 - val_loss: 0.0779 - val_sparse_categorical_accuracy: 0.9723 - lr: 2.5000e-04\n",
      "Epoch 132/500\n",
      "90/90 [==============================] - 5s 59ms/step - loss: 0.0726 - sparse_categorical_accuracy: 0.9753 - val_loss: 0.0761 - val_sparse_categorical_accuracy: 0.9709 - lr: 2.5000e-04\n",
      "Epoch 133/500\n",
      "90/90 [==============================] - 5s 55ms/step - loss: 0.0787 - sparse_categorical_accuracy: 0.9733 - val_loss: 0.0953 - val_sparse_categorical_accuracy: 0.9612 - lr: 2.5000e-04\n",
      "Epoch 134/500\n",
      "90/90 [==============================] - 4s 50ms/step - loss: 0.0763 - sparse_categorical_accuracy: 0.9753 - val_loss: 0.1018 - val_sparse_categorical_accuracy: 0.9653 - lr: 2.5000e-04\n",
      "Epoch 135/500\n",
      "90/90 [==============================] - 5s 55ms/step - loss: 0.0820 - sparse_categorical_accuracy: 0.9705 - val_loss: 0.1417 - val_sparse_categorical_accuracy: 0.9431 - lr: 2.5000e-04\n",
      "Epoch 136/500\n",
      "90/90 [==============================] - 5s 56ms/step - loss: 0.0717 - sparse_categorical_accuracy: 0.9764 - val_loss: 0.1313 - val_sparse_categorical_accuracy: 0.9417 - lr: 2.5000e-04\n",
      "Epoch 137/500\n",
      "90/90 [==============================] - 6s 62ms/step - loss: 0.0758 - sparse_categorical_accuracy: 0.9747 - val_loss: 0.1337 - val_sparse_categorical_accuracy: 0.9528 - lr: 2.5000e-04\n",
      "Epoch 138/500\n",
      "90/90 [==============================] - 5s 55ms/step - loss: 0.0813 - sparse_categorical_accuracy: 0.9733 - val_loss: 0.0793 - val_sparse_categorical_accuracy: 0.9667 - lr: 2.5000e-04\n",
      "Epoch 139/500\n",
      "90/90 [==============================] - 6s 65ms/step - loss: 0.0742 - sparse_categorical_accuracy: 0.9753 - val_loss: 0.0883 - val_sparse_categorical_accuracy: 0.9695 - lr: 2.5000e-04\n",
      "Epoch 140/500\n",
      "90/90 [==============================] - 5s 58ms/step - loss: 0.0771 - sparse_categorical_accuracy: 0.9764 - val_loss: 0.2310 - val_sparse_categorical_accuracy: 0.8988 - lr: 2.5000e-04\n",
      "Epoch 141/500\n",
      "90/90 [==============================] - 7s 77ms/step - loss: 0.0805 - sparse_categorical_accuracy: 0.9715 - val_loss: 0.1486 - val_sparse_categorical_accuracy: 0.9376 - lr: 2.5000e-04\n",
      "Epoch 142/500\n",
      "90/90 [==============================] - 5s 54ms/step - loss: 0.0748 - sparse_categorical_accuracy: 0.9764 - val_loss: 0.0977 - val_sparse_categorical_accuracy: 0.9584 - lr: 2.5000e-04\n",
      "Epoch 143/500\n",
      "90/90 [==============================] - 5s 52ms/step - loss: 0.0723 - sparse_categorical_accuracy: 0.9764 - val_loss: 0.1164 - val_sparse_categorical_accuracy: 0.9528 - lr: 2.5000e-04\n",
      "Epoch 144/500\n",
      "90/90 [==============================] - 5s 52ms/step - loss: 0.0813 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.1277 - val_sparse_categorical_accuracy: 0.9431 - lr: 2.5000e-04\n",
      "Epoch 145/500\n",
      "90/90 [==============================] - 6s 66ms/step - loss: 0.0779 - sparse_categorical_accuracy: 0.9733 - val_loss: 0.0873 - val_sparse_categorical_accuracy: 0.9653 - lr: 2.5000e-04\n",
      "Epoch 146/500\n",
      "90/90 [==============================] - 6s 72ms/step - loss: 0.0771 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.0792 - val_sparse_categorical_accuracy: 0.9736 - lr: 2.5000e-04\n",
      "Epoch 147/500\n",
      "90/90 [==============================] - 5s 53ms/step - loss: 0.0733 - sparse_categorical_accuracy: 0.9771 - val_loss: 0.3303 - val_sparse_categorical_accuracy: 0.8655 - lr: 2.5000e-04\n",
      "Epoch 148/500\n",
      "90/90 [==============================] - 4s 48ms/step - loss: 0.0788 - sparse_categorical_accuracy: 0.9750 - val_loss: 0.0979 - val_sparse_categorical_accuracy: 0.9639 - lr: 2.5000e-04\n",
      "Epoch 149/500\n",
      "90/90 [==============================] - 5s 50ms/step - loss: 0.0713 - sparse_categorical_accuracy: 0.9771 - val_loss: 0.0857 - val_sparse_categorical_accuracy: 0.9667 - lr: 2.5000e-04\n",
      "Epoch 150/500\n",
      "90/90 [==============================] - 5s 52ms/step - loss: 0.0753 - sparse_categorical_accuracy: 0.9764 - val_loss: 0.0860 - val_sparse_categorical_accuracy: 0.9709 - lr: 2.5000e-04\n",
      "Epoch 151/500\n",
      "90/90 [==============================] - 5s 50ms/step - loss: 0.0732 - sparse_categorical_accuracy: 0.9760 - val_loss: 0.1118 - val_sparse_categorical_accuracy: 0.9556 - lr: 2.5000e-04\n",
      "Epoch 152/500\n",
      "90/90 [==============================] - 6s 71ms/step - loss: 0.0752 - sparse_categorical_accuracy: 0.9736 - val_loss: 0.0819 - val_sparse_categorical_accuracy: 0.9695 - lr: 2.5000e-04\n",
      "Epoch 153/500\n",
      "90/90 [==============================] - 5s 58ms/step - loss: 0.0724 - sparse_categorical_accuracy: 0.9778 - val_loss: 0.0772 - val_sparse_categorical_accuracy: 0.9723 - lr: 1.2500e-04\n",
      "Epoch 154/500\n",
      "90/90 [==============================] - 5s 51ms/step - loss: 0.0731 - sparse_categorical_accuracy: 0.9760 - val_loss: 0.0793 - val_sparse_categorical_accuracy: 0.9750 - lr: 1.2500e-04\n",
      "Epoch 155/500\n",
      "90/90 [==============================] - 5s 55ms/step - loss: 0.0719 - sparse_categorical_accuracy: 0.9747 - val_loss: 0.0751 - val_sparse_categorical_accuracy: 0.9736 - lr: 1.2500e-04\n",
      "Epoch 156/500\n",
      "90/90 [==============================] - 5s 51ms/step - loss: 0.0764 - sparse_categorical_accuracy: 0.9743 - val_loss: 0.0851 - val_sparse_categorical_accuracy: 0.9626 - lr: 1.2500e-04\n",
      "Epoch 157/500\n",
      "90/90 [==============================] - 5s 52ms/step - loss: 0.0682 - sparse_categorical_accuracy: 0.9781 - val_loss: 0.0996 - val_sparse_categorical_accuracy: 0.9612 - lr: 1.2500e-04\n",
      "Epoch 158/500\n",
      "90/90 [==============================] - 5s 52ms/step - loss: 0.0727 - sparse_categorical_accuracy: 0.9771 - val_loss: 0.0774 - val_sparse_categorical_accuracy: 0.9723 - lr: 1.2500e-04\n",
      "Epoch 159/500\n",
      "90/90 [==============================] - 5s 57ms/step - loss: 0.0713 - sparse_categorical_accuracy: 0.9743 - val_loss: 0.0807 - val_sparse_categorical_accuracy: 0.9667 - lr: 1.2500e-04\n",
      "Epoch 160/500\n",
      "90/90 [==============================] - 5s 52ms/step - loss: 0.0725 - sparse_categorical_accuracy: 0.9726 - val_loss: 0.0809 - val_sparse_categorical_accuracy: 0.9653 - lr: 1.2500e-04\n",
      "Epoch 161/500\n",
      "90/90 [==============================] - 6s 62ms/step - loss: 0.0705 - sparse_categorical_accuracy: 0.9785 - val_loss: 0.0807 - val_sparse_categorical_accuracy: 0.9667 - lr: 1.2500e-04\n",
      "Epoch 162/500\n",
      "90/90 [==============================] - 5s 60ms/step - loss: 0.0750 - sparse_categorical_accuracy: 0.9729 - val_loss: 0.0764 - val_sparse_categorical_accuracy: 0.9764 - lr: 1.2500e-04\n",
      "Epoch 163/500\n",
      "90/90 [==============================] - 5s 56ms/step - loss: 0.0681 - sparse_categorical_accuracy: 0.9781 - val_loss: 0.0814 - val_sparse_categorical_accuracy: 0.9723 - lr: 1.2500e-04\n",
      "Epoch 164/500\n",
      "90/90 [==============================] - 5s 57ms/step - loss: 0.0699 - sparse_categorical_accuracy: 0.9781 - val_loss: 0.0776 - val_sparse_categorical_accuracy: 0.9695 - lr: 1.2500e-04\n",
      "Epoch 165/500\n",
      "90/90 [==============================] - 6s 65ms/step - loss: 0.0681 - sparse_categorical_accuracy: 0.9771 - val_loss: 0.0791 - val_sparse_categorical_accuracy: 0.9639 - lr: 1.2500e-04\n",
      "Epoch 166/500\n",
      "90/90 [==============================] - 5s 57ms/step - loss: 0.0740 - sparse_categorical_accuracy: 0.9778 - val_loss: 0.0977 - val_sparse_categorical_accuracy: 0.9709 - lr: 1.2500e-04\n",
      "Epoch 167/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 5s 56ms/step - loss: 0.0714 - sparse_categorical_accuracy: 0.9747 - val_loss: 0.0833 - val_sparse_categorical_accuracy: 0.9626 - lr: 1.2500e-04\n",
      "Epoch 168/500\n",
      "90/90 [==============================] - 5s 54ms/step - loss: 0.0685 - sparse_categorical_accuracy: 0.9767 - val_loss: 0.0897 - val_sparse_categorical_accuracy: 0.9653 - lr: 1.2500e-04\n",
      "Epoch 169/500\n",
      "90/90 [==============================] - 5s 55ms/step - loss: 0.0786 - sparse_categorical_accuracy: 0.9726 - val_loss: 0.0834 - val_sparse_categorical_accuracy: 0.9709 - lr: 1.2500e-04\n",
      "Epoch 170/500\n",
      "90/90 [==============================] - 5s 53ms/step - loss: 0.0707 - sparse_categorical_accuracy: 0.9785 - val_loss: 0.0847 - val_sparse_categorical_accuracy: 0.9653 - lr: 1.2500e-04\n",
      "Epoch 171/500\n",
      "90/90 [==============================] - 5s 54ms/step - loss: 0.0691 - sparse_categorical_accuracy: 0.9781 - val_loss: 0.0846 - val_sparse_categorical_accuracy: 0.9709 - lr: 1.2500e-04\n",
      "Epoch 172/500\n",
      "90/90 [==============================] - 5s 52ms/step - loss: 0.0682 - sparse_categorical_accuracy: 0.9774 - val_loss: 0.0840 - val_sparse_categorical_accuracy: 0.9723 - lr: 1.2500e-04\n",
      "Epoch 173/500\n",
      "90/90 [==============================] - 5s 53ms/step - loss: 0.0740 - sparse_categorical_accuracy: 0.9740 - val_loss: 0.0851 - val_sparse_categorical_accuracy: 0.9681 - lr: 1.2500e-04\n",
      "Epoch 174/500\n",
      "90/90 [==============================] - 5s 54ms/step - loss: 0.0685 - sparse_categorical_accuracy: 0.9792 - val_loss: 0.0797 - val_sparse_categorical_accuracy: 0.9695 - lr: 1.2500e-04\n",
      "Epoch 175/500\n",
      "90/90 [==============================] - 5s 51ms/step - loss: 0.0763 - sparse_categorical_accuracy: 0.9733 - val_loss: 0.0791 - val_sparse_categorical_accuracy: 0.9709 - lr: 1.2500e-04\n",
      "Epoch 176/500\n",
      "90/90 [==============================] - 5s 52ms/step - loss: 0.0657 - sparse_categorical_accuracy: 0.9792 - val_loss: 0.0759 - val_sparse_categorical_accuracy: 0.9695 - lr: 1.0000e-04\n",
      "Epoch 177/500\n",
      "90/90 [==============================] - 5s 52ms/step - loss: 0.0743 - sparse_categorical_accuracy: 0.9757 - val_loss: 0.0830 - val_sparse_categorical_accuracy: 0.9723 - lr: 1.0000e-04\n",
      "Epoch 178/500\n",
      "90/90 [==============================] - 6s 67ms/step - loss: 0.0700 - sparse_categorical_accuracy: 0.9778 - val_loss: 0.0801 - val_sparse_categorical_accuracy: 0.9695 - lr: 1.0000e-04\n",
      "Epoch 179/500\n",
      "90/90 [==============================] - 5s 58ms/step - loss: 0.0686 - sparse_categorical_accuracy: 0.9819 - val_loss: 0.0808 - val_sparse_categorical_accuracy: 0.9723 - lr: 1.0000e-04\n",
      "Epoch 180/500\n",
      "90/90 [==============================] - 5s 51ms/step - loss: 0.0712 - sparse_categorical_accuracy: 0.9771 - val_loss: 0.0790 - val_sparse_categorical_accuracy: 0.9667 - lr: 1.0000e-04\n",
      "Epoch 181/500\n",
      "90/90 [==============================] - 5s 52ms/step - loss: 0.0655 - sparse_categorical_accuracy: 0.9806 - val_loss: 0.0831 - val_sparse_categorical_accuracy: 0.9695 - lr: 1.0000e-04\n",
      "Epoch 182/500\n",
      "90/90 [==============================] - 5s 52ms/step - loss: 0.0666 - sparse_categorical_accuracy: 0.9799 - val_loss: 0.0803 - val_sparse_categorical_accuracy: 0.9667 - lr: 1.0000e-04\n",
      "Epoch 183/500\n",
      "90/90 [==============================] - 5s 54ms/step - loss: 0.0733 - sparse_categorical_accuracy: 0.9757 - val_loss: 0.0745 - val_sparse_categorical_accuracy: 0.9723 - lr: 1.0000e-04\n",
      "Epoch 184/500\n",
      "90/90 [==============================] - 5s 60ms/step - loss: 0.0732 - sparse_categorical_accuracy: 0.9733 - val_loss: 0.0819 - val_sparse_categorical_accuracy: 0.9709 - lr: 1.0000e-04\n",
      "Epoch 185/500\n",
      "90/90 [==============================] - 5s 57ms/step - loss: 0.0691 - sparse_categorical_accuracy: 0.9764 - val_loss: 0.0846 - val_sparse_categorical_accuracy: 0.9653 - lr: 1.0000e-04\n",
      "Epoch 186/500\n",
      "90/90 [==============================] - 5s 52ms/step - loss: 0.0707 - sparse_categorical_accuracy: 0.9792 - val_loss: 0.0853 - val_sparse_categorical_accuracy: 0.9612 - lr: 1.0000e-04\n",
      "Epoch 187/500\n",
      "90/90 [==============================] - 5s 50ms/step - loss: 0.0667 - sparse_categorical_accuracy: 0.9788 - val_loss: 0.0806 - val_sparse_categorical_accuracy: 0.9667 - lr: 1.0000e-04\n",
      "Epoch 188/500\n",
      "90/90 [==============================] - 5s 51ms/step - loss: 0.0685 - sparse_categorical_accuracy: 0.9802 - val_loss: 0.0775 - val_sparse_categorical_accuracy: 0.9750 - lr: 1.0000e-04\n",
      "Epoch 189/500\n",
      "90/90 [==============================] - 5s 55ms/step - loss: 0.0679 - sparse_categorical_accuracy: 0.9757 - val_loss: 0.0790 - val_sparse_categorical_accuracy: 0.9750 - lr: 1.0000e-04\n",
      "Epoch 190/500\n",
      "90/90 [==============================] - 5s 52ms/step - loss: 0.0672 - sparse_categorical_accuracy: 0.9771 - val_loss: 0.0971 - val_sparse_categorical_accuracy: 0.9653 - lr: 1.0000e-04\n",
      "Epoch 191/500\n",
      "90/90 [==============================] - 5s 53ms/step - loss: 0.0712 - sparse_categorical_accuracy: 0.9747 - val_loss: 0.0778 - val_sparse_categorical_accuracy: 0.9709 - lr: 1.0000e-04\n",
      "Epoch 192/500\n",
      "90/90 [==============================] - 7s 78ms/step - loss: 0.0706 - sparse_categorical_accuracy: 0.9733 - val_loss: 0.0775 - val_sparse_categorical_accuracy: 0.9695 - lr: 1.0000e-04\n",
      "Epoch 193/500\n",
      "90/90 [==============================] - 5s 59ms/step - loss: 0.0640 - sparse_categorical_accuracy: 0.9809 - val_loss: 0.0828 - val_sparse_categorical_accuracy: 0.9681 - lr: 1.0000e-04\n",
      "Epoch 194/500\n",
      "90/90 [==============================] - 5s 54ms/step - loss: 0.0688 - sparse_categorical_accuracy: 0.9753 - val_loss: 0.0775 - val_sparse_categorical_accuracy: 0.9723 - lr: 1.0000e-04\n",
      "Epoch 195/500\n",
      "90/90 [==============================] - 5s 55ms/step - loss: 0.0674 - sparse_categorical_accuracy: 0.9760 - val_loss: 0.0842 - val_sparse_categorical_accuracy: 0.9709 - lr: 1.0000e-04\n",
      "Epoch 196/500\n",
      "90/90 [==============================] - 5s 55ms/step - loss: 0.0676 - sparse_categorical_accuracy: 0.9778 - val_loss: 0.0773 - val_sparse_categorical_accuracy: 0.9736 - lr: 1.0000e-04\n",
      "Epoch 197/500\n",
      "90/90 [==============================] - 5s 52ms/step - loss: 0.0680 - sparse_categorical_accuracy: 0.9781 - val_loss: 0.0751 - val_sparse_categorical_accuracy: 0.9723 - lr: 1.0000e-04\n",
      "Epoch 198/500\n",
      "90/90 [==============================] - 5s 54ms/step - loss: 0.0652 - sparse_categorical_accuracy: 0.9781 - val_loss: 0.0753 - val_sparse_categorical_accuracy: 0.9695 - lr: 1.0000e-04\n",
      "Epoch 199/500\n",
      "90/90 [==============================] - 5s 52ms/step - loss: 0.0652 - sparse_categorical_accuracy: 0.9788 - val_loss: 0.1163 - val_sparse_categorical_accuracy: 0.9556 - lr: 1.0000e-04\n",
      "Epoch 200/500\n",
      "90/90 [==============================] - 5s 55ms/step - loss: 0.0625 - sparse_categorical_accuracy: 0.9809 - val_loss: 0.0777 - val_sparse_categorical_accuracy: 0.9695 - lr: 1.0000e-04\n",
      "Epoch 201/500\n",
      "90/90 [==============================] - 5s 51ms/step - loss: 0.0632 - sparse_categorical_accuracy: 0.9799 - val_loss: 0.0770 - val_sparse_categorical_accuracy: 0.9695 - lr: 1.0000e-04\n",
      "Epoch 202/500\n",
      "90/90 [==============================] - 5s 52ms/step - loss: 0.0671 - sparse_categorical_accuracy: 0.9767 - val_loss: 0.0771 - val_sparse_categorical_accuracy: 0.9695 - lr: 1.0000e-04\n",
      "Epoch 203/500\n",
      "90/90 [==============================] - 5s 51ms/step - loss: 0.0643 - sparse_categorical_accuracy: 0.9795 - val_loss: 0.0774 - val_sparse_categorical_accuracy: 0.9653 - lr: 1.0000e-04\n",
      "Epoch 204/500\n",
      "90/90 [==============================] - 5s 55ms/step - loss: 0.0653 - sparse_categorical_accuracy: 0.9778 - val_loss: 0.0783 - val_sparse_categorical_accuracy: 0.9681 - lr: 1.0000e-04\n",
      "Epoch 205/500\n",
      "90/90 [==============================] - 7s 74ms/step - loss: 0.0639 - sparse_categorical_accuracy: 0.9826 - val_loss: 0.0796 - val_sparse_categorical_accuracy: 0.9736 - lr: 1.0000e-04\n",
      "Epoch 206/500\n",
      "90/90 [==============================] - 5s 61ms/step - loss: 0.0637 - sparse_categorical_accuracy: 0.9799 - val_loss: 0.0768 - val_sparse_categorical_accuracy: 0.9723 - lr: 1.0000e-04\n",
      "Epoch 207/500\n",
      "90/90 [==============================] - 5s 58ms/step - loss: 0.0633 - sparse_categorical_accuracy: 0.9806 - val_loss: 0.0822 - val_sparse_categorical_accuracy: 0.9667 - lr: 1.0000e-04\n",
      "Epoch 208/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 6s 61ms/step - loss: 0.0672 - sparse_categorical_accuracy: 0.9785 - val_loss: 0.0868 - val_sparse_categorical_accuracy: 0.9695 - lr: 1.0000e-04\n",
      "Epoch 209/500\n",
      "90/90 [==============================] - 6s 67ms/step - loss: 0.0679 - sparse_categorical_accuracy: 0.9792 - val_loss: 0.0773 - val_sparse_categorical_accuracy: 0.9695 - lr: 1.0000e-04\n",
      "Epoch 210/500\n",
      "90/90 [==============================] - 6s 61ms/step - loss: 0.0637 - sparse_categorical_accuracy: 0.9785 - val_loss: 0.0894 - val_sparse_categorical_accuracy: 0.9695 - lr: 1.0000e-04\n",
      "Epoch 211/500\n",
      "90/90 [==============================] - 5s 53ms/step - loss: 0.0646 - sparse_categorical_accuracy: 0.9778 - val_loss: 0.0840 - val_sparse_categorical_accuracy: 0.9709 - lr: 1.0000e-04\n",
      "Epoch 212/500\n",
      "90/90 [==============================] - 5s 55ms/step - loss: 0.0657 - sparse_categorical_accuracy: 0.9785 - val_loss: 0.0808 - val_sparse_categorical_accuracy: 0.9723 - lr: 1.0000e-04\n",
      "Epoch 213/500\n",
      "90/90 [==============================] - 5s 51ms/step - loss: 0.0639 - sparse_categorical_accuracy: 0.9792 - val_loss: 0.0749 - val_sparse_categorical_accuracy: 0.9764 - lr: 1.0000e-04\n",
      "Epoch 214/500\n",
      "90/90 [==============================] - 5s 54ms/step - loss: 0.0618 - sparse_categorical_accuracy: 0.9799 - val_loss: 0.0781 - val_sparse_categorical_accuracy: 0.9653 - lr: 1.0000e-04\n",
      "Epoch 215/500\n",
      "90/90 [==============================] - 5s 57ms/step - loss: 0.0663 - sparse_categorical_accuracy: 0.9785 - val_loss: 0.0818 - val_sparse_categorical_accuracy: 0.9681 - lr: 1.0000e-04\n",
      "Epoch 216/500\n",
      "90/90 [==============================] - 5s 53ms/step - loss: 0.0632 - sparse_categorical_accuracy: 0.9795 - val_loss: 0.0796 - val_sparse_categorical_accuracy: 0.9667 - lr: 1.0000e-04\n",
      "Epoch 217/500\n",
      "90/90 [==============================] - 5s 57ms/step - loss: 0.0704 - sparse_categorical_accuracy: 0.9760 - val_loss: 0.0760 - val_sparse_categorical_accuracy: 0.9653 - lr: 1.0000e-04\n",
      "Epoch 218/500\n",
      "90/90 [==============================] - 6s 64ms/step - loss: 0.0657 - sparse_categorical_accuracy: 0.9771 - val_loss: 0.0805 - val_sparse_categorical_accuracy: 0.9667 - lr: 1.0000e-04\n",
      "Epoch 219/500\n",
      "90/90 [==============================] - 5s 57ms/step - loss: 0.0683 - sparse_categorical_accuracy: 0.9774 - val_loss: 0.0803 - val_sparse_categorical_accuracy: 0.9612 - lr: 1.0000e-04\n",
      "Epoch 220/500\n",
      "90/90 [==============================] - 5s 55ms/step - loss: 0.0688 - sparse_categorical_accuracy: 0.9747 - val_loss: 0.0843 - val_sparse_categorical_accuracy: 0.9653 - lr: 1.0000e-04\n",
      "Epoch 221/500\n",
      "90/90 [==============================] - 5s 60ms/step - loss: 0.0606 - sparse_categorical_accuracy: 0.9806 - val_loss: 0.0758 - val_sparse_categorical_accuracy: 0.9681 - lr: 1.0000e-04\n",
      "Epoch 222/500\n",
      "90/90 [==============================] - 5s 56ms/step - loss: 0.0695 - sparse_categorical_accuracy: 0.9771 - val_loss: 0.0766 - val_sparse_categorical_accuracy: 0.9695 - lr: 1.0000e-04\n",
      "Epoch 223/500\n",
      "90/90 [==============================] - 5s 55ms/step - loss: 0.0706 - sparse_categorical_accuracy: 0.9771 - val_loss: 0.0791 - val_sparse_categorical_accuracy: 0.9709 - lr: 1.0000e-04\n",
      "Epoch 224/500\n",
      "90/90 [==============================] - 5s 54ms/step - loss: 0.0663 - sparse_categorical_accuracy: 0.9781 - val_loss: 0.1145 - val_sparse_categorical_accuracy: 0.9556 - lr: 1.0000e-04\n",
      "Epoch 225/500\n",
      "90/90 [==============================] - 6s 63ms/step - loss: 0.0630 - sparse_categorical_accuracy: 0.9788 - val_loss: 0.0758 - val_sparse_categorical_accuracy: 0.9709 - lr: 1.0000e-04\n",
      "Epoch 226/500\n",
      "90/90 [==============================] - 5s 52ms/step - loss: 0.0670 - sparse_categorical_accuracy: 0.9774 - val_loss: 0.1071 - val_sparse_categorical_accuracy: 0.9542 - lr: 1.0000e-04\n",
      "Epoch 227/500\n",
      "90/90 [==============================] - 5s 54ms/step - loss: 0.0620 - sparse_categorical_accuracy: 0.9816 - val_loss: 0.0750 - val_sparse_categorical_accuracy: 0.9681 - lr: 1.0000e-04\n",
      "Epoch 228/500\n",
      "90/90 [==============================] - 5s 52ms/step - loss: 0.0618 - sparse_categorical_accuracy: 0.9809 - val_loss: 0.0853 - val_sparse_categorical_accuracy: 0.9653 - lr: 1.0000e-04\n",
      "Epoch 229/500\n",
      "90/90 [==============================] - 5s 54ms/step - loss: 0.0638 - sparse_categorical_accuracy: 0.9809 - val_loss: 0.0773 - val_sparse_categorical_accuracy: 0.9695 - lr: 1.0000e-04\n",
      "Epoch 230/500\n",
      "90/90 [==============================] - 5s 57ms/step - loss: 0.0626 - sparse_categorical_accuracy: 0.9816 - val_loss: 0.0924 - val_sparse_categorical_accuracy: 0.9667 - lr: 1.0000e-04\n",
      "Epoch 231/500\n",
      "90/90 [==============================] - 6s 66ms/step - loss: 0.0626 - sparse_categorical_accuracy: 0.9799 - val_loss: 0.0802 - val_sparse_categorical_accuracy: 0.9667 - lr: 1.0000e-04\n",
      "Epoch 232/500\n",
      "90/90 [==============================] - 6s 63ms/step - loss: 0.0637 - sparse_categorical_accuracy: 0.9809 - val_loss: 0.0849 - val_sparse_categorical_accuracy: 0.9653 - lr: 1.0000e-04\n",
      "Epoch 233/500\n",
      "90/90 [==============================] - 5s 60ms/step - loss: 0.0660 - sparse_categorical_accuracy: 0.9792 - val_loss: 0.0864 - val_sparse_categorical_accuracy: 0.9667 - lr: 1.0000e-04\n",
      "Epoch 233: early stopping\n"
     ]
    }
   ],
   "source": [
    "epochs = 500\n",
    "batch_size = 32\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        \"best_model.keras\", save_best_only=True, monitor=\"val_loss\" # \"best_model.h5\"\n",
    "    ),\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor=\"val_loss\", factor=0.5, patience=20, min_lr=0.0001\n",
    "    ),\n",
    "    keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=50, verbose=1),\n",
    "]\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"sparse_categorical_accuracy\"],\n",
    ")\n",
    "# model estymuje się 20-30 minut\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks,\n",
    "    validation_split=0.2,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a35ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metric = \"sparse_categorical_accuracy\"\n",
    "\n",
    "# plt.plot(history.history[metric])\n",
    "# plt.plot(history.history[\"val_\" + metric])\n",
    "# plt.title(\"model \" + metric)\n",
    "# plt.ylabel(metric, fontsize=\"large\")\n",
    "# plt.xlabel(\"epoch\", fontsize=\"large\")\n",
    "# plt.legend([\"train\", \"val\"], loc=\"best\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f941da",
   "metadata": {},
   "source": [
    "### Ewaluacja modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74acadc8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 12ms/step - loss: 0.0904 - sparse_categorical_accuracy: 0.9727\n",
      "Test accuracy 0.9727272987365723\n",
      "Test loss 0.09036418795585632\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model(\"best_model.keras\")\n",
    "\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "\n",
    "print(\"Test accuracy\", test_acc)\n",
    "print(\"Test loss\", test_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a7c405",
   "metadata": {},
   "source": [
    "# 3 Przykład aplikacyjny - Natural Language Processing\n",
    "\n",
    "Źródło: \n",
    "* https://machinelearningmastery.com/predict-sentiment-movie-reviews-using-deep-learning/\n",
    "* https://builtin.com/data-science/how-build-neural-network-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e76d9d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ce189da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000,) (25000,)\n",
      "(25000,) (25000,)\n"
     ]
    }
   ],
   "source": [
    "# Wczytanie danych\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=5000) # wczytanie tylko 5 tys. najpopularniejszych słów\n",
    "print(X_train.shape, X_test.shape)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac34d07e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Typ obiektu\n",
    "type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7beae3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 2, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 2, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 2, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 2, 19, 178, 32]\n"
     ]
    }
   ],
   "source": [
    "# Struktura pojedynczej obserwacji:\n",
    "# - zamiast słów numery (każdy numer to inne słowo)\n",
    "# - słowa (numery) są w kolejności, w jakiej oryginalnie były zapisane w recenzji\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "212fa114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert # is an amazing actor and now the same being director # father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for # and would recommend it to everyone to watch and the fly # was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also # to the two little # that played the # of norman and paul they were just brilliant children are often left out of the # list i think because the stars that play them all grown up are such a big # for the whole film but these children are amazing and should be # for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was # with us all\n"
     ]
    }
   ],
   "source": [
    "# Odkodujmy jedną recenzję:\n",
    "index = imdb.get_word_index()\n",
    "reverse_index = dict([(value, key) for (key, value) in index.items()]) \n",
    "decoded = \" \".join( [reverse_index.get(i - 3, \"#\") for i in X_train[0]] )\n",
    "print(decoded) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95701cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jak długie są recenzje?\n",
    "dl_recenzji = np.array([len(x) for x in X_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "53896edf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DescribeResult(nobs=25000, minmax=(11, 2494), mean=238.71364, variance=31151.26288846594, skewness=2.1551798363406474, kurtosis=6.648704130934446)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# od 11 do 2494 słów\n",
    "from scipy import stats\n",
    "stats.describe(dl_recenzji)\n",
    "\n",
    "# Co to oznacza? że jak przekształcimy w tabelę płaską, każda obserwacja będzie miała inne wymiary - musimy zestandaryzować długość każ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e4f4b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ograniczenie pojedynczej recenzji do 500 pierwszych słów\n",
    "max_words = 500\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_words)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "03c51b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\peter_c\\AppData\\Local\\Temp\\ipykernel_13572\\1910084082.py:2: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  stats.describe(dl_recenzji)\n",
      "C:\\Users\\peter_c\\miniconda3\\envs\\ds\\lib\\site-packages\\scipy\\stats\\_stats_py.py:1522: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  sk = skew(a, axis, bias=bias)\n",
      "C:\\Users\\peter_c\\miniconda3\\envs\\ds\\lib\\site-packages\\scipy\\stats\\_stats_py.py:1523: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  kurt = kurtosis(a, axis, bias=bias)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DescribeResult(nobs=25000, minmax=(500, 500), mean=500.0, variance=0.0, skewness=nan, kurtosis=nan)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl_recenzji = np.array([len(x) for x in X_train])\n",
    "stats.describe(dl_recenzji)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18befbd2",
   "metadata": {},
   "source": [
    "Skonstruujmy najprostszy model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "25ded52b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_5 (Conv1D)           (None, 500, 32)           128       \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPooling  (None, 250, 32)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 8000)              0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 250)               2000250   \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 251       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,000,629\n",
      "Trainable params: 2,000,629\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Input(shape=(500, 1)))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b387ec",
   "metadata": {},
   "source": [
    "Estymacja i ewaluacja modelu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c59ce740",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "196/196 - 13s - loss: 10.4683 - accuracy: 0.5019 - val_loss: 0.7030 - val_accuracy: 0.5028 - 13s/epoch - 64ms/step\n",
      "Epoch 2/20\n",
      "196/196 - 8s - loss: 0.6960 - accuracy: 0.5044 - val_loss: 0.7339 - val_accuracy: 0.5019 - 8s/epoch - 40ms/step\n",
      "Epoch 3/20\n",
      "196/196 - 8s - loss: 0.6942 - accuracy: 0.5050 - val_loss: 0.6981 - val_accuracy: 0.5011 - 8s/epoch - 41ms/step\n",
      "Epoch 4/20\n",
      "196/196 - 11s - loss: 0.6913 - accuracy: 0.5033 - val_loss: 0.6975 - val_accuracy: 0.5005 - 11s/epoch - 58ms/step\n",
      "Epoch 5/20\n",
      "196/196 - 13s - loss: 0.6902 - accuracy: 0.5077 - val_loss: 0.6983 - val_accuracy: 0.5006 - 13s/epoch - 65ms/step\n",
      "Epoch 6/20\n",
      "196/196 - 13s - loss: 0.6888 - accuracy: 0.5061 - val_loss: 0.6981 - val_accuracy: 0.5009 - 13s/epoch - 65ms/step\n",
      "Epoch 7/20\n",
      "196/196 - 13s - loss: 0.6873 - accuracy: 0.4988 - val_loss: 0.7034 - val_accuracy: 0.5014 - 13s/epoch - 66ms/step\n",
      "Epoch 8/20\n",
      "196/196 - 7s - loss: 0.6870 - accuracy: 0.5090 - val_loss: 0.7083 - val_accuracy: 0.5023 - 7s/epoch - 34ms/step\n",
      "Epoch 9/20\n",
      "196/196 - 7s - loss: 0.6897 - accuracy: 0.5076 - val_loss: 0.7065 - val_accuracy: 0.5010 - 7s/epoch - 36ms/step\n",
      "Epoch 10/20\n",
      "196/196 - 10s - loss: 0.6864 - accuracy: 0.5119 - val_loss: 0.7005 - val_accuracy: 0.4989 - 10s/epoch - 49ms/step\n",
      "Epoch 11/20\n",
      "196/196 - 12s - loss: 0.6871 - accuracy: 0.5128 - val_loss: 0.7021 - val_accuracy: 0.5003 - 12s/epoch - 60ms/step\n",
      "Epoch 12/20\n",
      "196/196 - 13s - loss: 0.6849 - accuracy: 0.5182 - val_loss: 0.7048 - val_accuracy: 0.4993 - 13s/epoch - 65ms/step\n",
      "Epoch 13/20\n",
      "196/196 - 10s - loss: 0.6841 - accuracy: 0.5180 - val_loss: 0.7068 - val_accuracy: 0.4984 - 10s/epoch - 53ms/step\n",
      "Epoch 14/20\n",
      "196/196 - 12s - loss: 0.6823 - accuracy: 0.5216 - val_loss: 0.7080 - val_accuracy: 0.4997 - 12s/epoch - 62ms/step\n",
      "Epoch 15/20\n",
      "196/196 - 7s - loss: 0.6821 - accuracy: 0.5221 - val_loss: 0.7078 - val_accuracy: 0.5012 - 7s/epoch - 35ms/step\n",
      "Epoch 16/20\n",
      "196/196 - 7s - loss: 0.6830 - accuracy: 0.5155 - val_loss: 0.7058 - val_accuracy: 0.4988 - 7s/epoch - 34ms/step\n",
      "Epoch 17/20\n",
      "196/196 - 13s - loss: 0.6803 - accuracy: 0.5249 - val_loss: 0.7154 - val_accuracy: 0.4993 - 13s/epoch - 65ms/step\n",
      "Epoch 18/20\n",
      "196/196 - 13s - loss: 0.6803 - accuracy: 0.5215 - val_loss: 0.7107 - val_accuracy: 0.4990 - 13s/epoch - 68ms/step\n",
      "Epoch 19/20\n",
      "196/196 - 12s - loss: 0.6797 - accuracy: 0.5250 - val_loss: 0.7176 - val_accuracy: 0.5002 - 12s/epoch - 60ms/step\n",
      "Epoch 20/20\n",
      "196/196 - 11s - loss: 0.6789 - accuracy: 0.5261 - val_loss: 0.7187 - val_accuracy: 0.4996 - 11s/epoch - 58ms/step\n",
      "Accuracy: 49.96%\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=20, batch_size=128, verbose=2)\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f803735",
   "metadata": {},
   "source": [
    "Niestety ta architektura nie działa - spróbujmy wykonać model z wektoryzacją tekstu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2839182a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 500, 32)           160000    \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 500, 32)           3104      \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 250, 32)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 8000)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 250)               2000250   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 251       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,163,605\n",
      "Trainable params: 2,163,605\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=5000, 32, input_length=500))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09504191",
   "metadata": {},
   "source": [
    "Estymacja i ewaluacja:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fafeb4ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "196/196 - 16s - loss: 0.5171 - accuracy: 0.7143 - val_loss: 0.3071 - val_accuracy: 0.8696 - 16s/epoch - 80ms/step\n",
      "Epoch 2/2\n",
      "196/196 - 11s - loss: 0.2298 - accuracy: 0.9088 - val_loss: 0.2850 - val_accuracy: 0.8796 - 11s/epoch - 57ms/step\n",
      "Accuracy: 87.96%\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=2, batch_size=128, verbose=2)\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62226c45",
   "metadata": {},
   "source": [
    "Do problemu wrócimy przy omawianiu algorytmu word2vec. Porównamy wtedy sieci CNN z word embedding."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
